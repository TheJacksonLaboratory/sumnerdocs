{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Template for HPC Sumner Documentation Work In Progress Documentation is in alpha stage and not intended for setting up Sumner HPC environment.","title":"Home"},{"location":"conda/S01_conda/","text":"Work In Progress Documentation is in alpha stage and not intended for setting up Sumner HPC environment. First-time Login \u00b6 1 2 3 4 5 ssh login.sumner.jax.org ## Know OS and kernel version cat /etc/redhat-release uname -a Running CentOS Linux release 7.7.1908 (Core) Linux sumner-log2 3.10.0-1062.1.2.el7.x86_64 #1 SMP Mon Sep 30 14:19:46 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux First, login to sumner with a clean env, i.e., as it ships with default profile from HPC team, and nothing added in following files. Default bash configuration for sumner looks similar to /confs/dotfiles/hpc_default_env/ . 1 2 3 4 ~/.bashrc ~/.bash_profile ~/.bash_aliases # if it exists ~/.profile # if it exists If you had custom bash configs (linuxbrew, previous conda, etc.), comment those out from above files. If you'd linuxbrew installed, make sure to disable it unless you are confident that conda and linuxbrew can work in harmony! Same goes for ~/.local/ directory which should not exist at the fresh startup. If it does, you may have installed some tools using python, perl, or other non-root based setup scripts. For clean setup, ~/.local directory needs to be removed from user environment, i.e., either rename it to say, ~/.local_deprecated or archive it somewhere! Make sure to logout and login to sumner again for a clean env to take an effect. Once you login, your env should look something similar to this one. Note that PATH variable will default to cent os 7 standard paths and LD_LIBRARY_PATH should preferably only contain entries related to slurm scheduler. 1 2 3 4 exit #from sumner ## login again ssh login.sumner.jax.org Check common env variables set by default (HPC team) 1 2 ## paths where all executables can be found echo $PATH 1 /cm/local/apps/gcc/8.2.0/bin:/cm/shared/apps/slurm/18.08.8/sbin:/cm/shared/apps/slurm/18.08.8/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:.:/home/yoda/.local/bin:/home/yoda/bin 1 2 ## paths where shared libraries are available to run programs echo $LD_LIBRARY_PATH 1 /cm/local/apps/gcc/8.2.0/lib:/cm/local/apps/gcc/8.2.0/lib64:/cm/shared/apps/slurm/18.08.8/lib64/slurm:/cm/shared/apps/slurm/18.08.8/lib64 1 2 3 ## Used by gcc before compiling program ## Read https://stackoverflow.com/a/4250666/1243763 echo $LIBRARY_PATH 1 /cm/shared/apps/slurm/18.08.8/lib64/slurm:/cm/shared/apps/slurm/18.08.8/lib64 1 2 3 ## default loaded modules ## Most of paths in PATH, LD_LIBRARY_PATH, and LIBRARY_PATH are configured by these loaded modules. module list Currently Loaded Modules: 1) shared 2) DefaultModules 3) dot 4) default-environment 5) slurm/18.08.8 6) gcc/8.2.0 Store default hpc configuration Useful to fall back to HPC defaults if something goes awry! 1 2 3 4 5 6 7 mkdir -p ~/bkup/confs/hpc_default_env/ cp .bashrc bkup/confs/hpc_default_env/ cp .bash_profile bkup/confs/hpc_default_env/ ## export global env env | tee -a ~/bkup/confs/hpc_default_env/default_hpc_env.txt dot module only appends . to PATH variable (see module show dot ), so that you do not need to prefix ./ to run an executable file under present working directory. Since I do not need dot module, I will override default module loading by doing module unload dot in my bash configuration (later). 1 module list For now, you may add following cmd to your ~/.bash_profile . Eventually it will go to ~/.profile.d/ setup detailed below. 1 module unload dot For now, I do not need system gcc and will rely on conda-installed gcc and other devtools x86_64-conda_cos6-linux-gnu-* . More on that later but let's unload gcc first. 1 2 module unload gcc module list 1 2 Currently Loaded Modules: 1) shared 2) DefaultModules 3) default-environment 4) slurm/18.08.8 Unloading gcc Note that while starting pseudo-terminal using screen, tmux, or slurm interactive job, you may get module loaded gcc again in PATH. If so, make sure to do module unload gcc before running setup further. Backup and Reset Dotfiles \u00b6 Move dotfiles to archived directory If you have dotfiles and/or dot directories like .Renviron, .Rprofile, .curlrc, .cache, .config, etc., that may cause issues configuring environment. Moving dotfiles Following is what I've done but may not be safe unless you know what you are doing! Moving some of dotfiles is tricky as they are required for login to sumner. If you are doing this, make sure NOT to logout of sumner and at the end of executing this code block on sumner, make sure that you can login from another terminal to sumner. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 ## WARN: Moving all files and directories starting ## with dot to archived dir. mkdir -p \" ${ HOME } \" /legacy_env && \\ mv \" ${ HOME } \" /. [ ^. ] * legacy_env/ ## DO NOT FORGET TO COPY BACK following files to ## \"${HOME}\"/ else you may get locked out of sumner. cd \" ${ HOME } \" && \\ echo \"You are in home directory at $( pwd ) \" ## sumner ssh dir rsync -avhP legacy_env/.ssh ./ ## sumner login tokens, if any cp legacy_env/.vas_* ./ cp legacy_env/.bash* ./ cp legacy_env/.ksh* ./ cp legacy_env/.k5login ./ rsync -avhP legacy_env/.pki ./ rsync -avhP legacy_env/.parallel ./ ## optional files, if any ## singularity may take a larger space rsync -avhP legacy_env/.singularity ./ rsync -avhP legacy_env/.subversion ./ cp legacy_env/.emacs ./ cp legacy_env/.viminfo ./ ## make empty dirs ## note that user .local and .config, if any are now backed up and ## we are creating a empty ~/.local directory mkdir -p \" ${ HOME } \" /.cache mkdir -p \" ${ HOME } \" /.config mkdir -p \" ${ HOME } \" /.local ## CONFIRM FROM A SEPARATE TERMINAL that you can login to sumner ssh yoda@sumner env If above command succeeds and env looks similar (PATH in particular) to PATH and LD_LIBRARY_PATH shown above, you're good! You can exit old sumner session and install anaconda3 in new terminal session. Start Interactive Job prior to installation Prefer running setup on a dedicated interactive node instead of login node. Some of conda install/update steps may get killed on login node. 1 srun -p compute -q batch -N 1 -n 3 --mem 10G -t 08 :00:00 --pty bash Install anaconda3 \u00b6 Python3 over Python2 Prefer using Anaconda3 (Python3) over Python2 as the latter has reached End of Life . For anaconda3: Using v2019.03-Linux-x86_64 with permalink and MD5 : b77a71c3712b45c8f33c7b2ecade366c. 1 2 3 4 5 cd \" $HOME \" && \\ mkdir -p Downloads/conda && \\ cd Downloads/conda && \\ wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ md5sum Anaconda3-2019.10-Linux-x86_64.sh Setup anaconda3 environment with default options, i.e., install at ~/anaconda3 . 1 2 cd \" $HOME \" && \\ bash ~/Downloads/conda/Anaconda3-2019.10-Linux-x86_64.sh Once conda installation is complete at default location, logout and login to sumner. Default conda env, base will now be in effect. Note (base) prefix to your username. Also, check output of following: 1 echo $CONDA_DEFAULT_ENV base 1 echo $CONDA_PREFIX /home/yoda/anaconda3 Configuring Conda \u00b6 Following are additional configuration within conda environment to enable installation of R 3.6.1+ and Jupyter. Set channel priority \u00b6 Important Prefer installing compilers only from a single channel and avoid mix-and-match install. Read more at conda-forge page on channel_priority: strict which is enabled at default for conda v4.6 or higher. Add Bioconda and conda-forge channels to get updated and compbio related packages. Avoid changing order of following commands unless you prefer to keep a different priority for these channels. 1 2 3 conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge Above command will generate ~/.condarc file and set priority for channels, i.e., when same package is available from more than one channels, we prioritize installation per ordered channel list in ~/.condarc file as shown below. This file should be present after above commands and no need to edit unless changing priority of channels. This is in yaml format file. Please take care of preceding spaces (and not tabs) before and after - while editing this file. 1 2 3 4 channels: - conda-forge - bioconda - defaults Install R 3.6.1 \u00b6 For compatibility with conda env, prefer installing R 3.6 via conda. Prefer installing R env from conda-forge channel which is already a priority channel in our ~/.condarc . We also specify R version, just to make sure that we install R v3.6.1. Beware of non-standard conda packages Note that most up-to-date R version may be available in the same or other conda channels, like r or bioconda but it is preferable to install R from the first priority channel, i.e., conda-forge in our case, and where package does not show non-standard labels at anaconda website, e.g., As of writing this section, R 3.6.2 on anaconda website shows use of non-standard labels, most likely because it was updated a few days before and so, may not comply with all of conda dependency. 1 2 3 4 ## look for a line r-base and check source channel. ## If it is other than conda-forge, try to downgrade R package where ## r-base is available under conda-forge channel. conda install -c conda-forge r-base = 3 .6.1 Above command will take 15-30 min to resolve dependencies. It will do major overhaul of default conda environment by... upgrading conda to latest version, 4.8.2 or higher. installing conda and r-base from conda-forge source. and much more... Pin R and conda auto-updates \u00b6 Before moving further, let's pin R version to 3.6.1 and also disallow conda auto-updates. That way, we have lesser chances of breaking conda env when we do conda install <pkg> in future, and carefully install/update packages without breaking existing setup. Compile over conda install Rpkg Typically, I avoid installing or updating package if conda install throws a message or warning about removing or downgrading existing packages. In such cases, I fall back to compiling package using available devtools in conda and sumner. Also, I load compiled package using Modulefile when needed, and not integrate it in my default bash environment as this may give errors while running some random program due to conflicts in shared library versions. 1 2 3 4 conda config --set auto_update_conda False ## add following to pinned file nano ~/anaconda3/conda-meta/pinned r-base ==3.6.1 Setup Rprofile and Renviron \u00b6 Setup R package directory path for R 3.6 1 mkdir -p ~/R/pkgs/v3.6 Create these two files to setup startup env for R Renviron 1 nano ~/.Renviron Where should R save new packages? Over time, this directory may grow in size, so better to keep under tier1 storage. 1 R_LIBS = \"/projects/verhaak-lab/yoda/sumnerenv_os7/R/pkgs/v3.6:/home/yoda/R/pkgs/v3.6:/home/yoda/anaconda3/lib/R/library\" You can confirm precedence of R library paths in R using .libPaths() command. Note that /home/yoda/anaconda3/lib/R/library is a required path set while installing R using conda. R profile 1 nano ~/.Rprofile 1 2 3 4 5 6 7 8 9 10 ## set user specific env variables, if any here ## e.g., GITHUB_PAT if here Sys.setenv(\"GITHUB_PAT\"=\"xyzabc1234\") ## Default source to download packages local({ r <- getOption(\"repos\") r[\"CRAN\"] <- \"https://cran.rstudio.com\" options(repos = r) }) Before further configuring sumner env, let's logout and login first from interactive job and exit sumner. Then, login back to sumner and start interactive queue again. 1 2 3 4 5 6 7 exit # from interactive session exit # from sumner ssh sumner ## start interactive session srun -p compute -q batch -N 1 -n 3 --mem 10G -t 08 :00:00 --pty bash Confirm that login env is similar to earlier env (just after anaconda3 setup) by running env command. PATH should now have paths related to conda env prefixed but nothing else related to modules, LD_LIBRARY_PATH, etc. Also, make sure that module: gcc is unloaded. We do not want system gcc (or any other devtools), and instead rely on conda-installed devtools. 1 2 3 4 5 6 ## unload gcc if loaded module unload gcc ## example PATH variable /home/yoda/anaconda3/bin:/home/yoda/anaconda3/condabin:/cm/shared/apps/slurm/18.08.8/sbin:/cm/shared/apps/slurm/18.08.8/bin :/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/yoda/.local/bin:/home/yoda/bin Avoid Rpkgs using conda install Install essential R packages and jupyter kernel for R only if they are available for R 3.6.x (preferably v3.6.1) from conda-forge channel. This may not be a case for most times, e.g., for R v3.5.1, I can find compatible packages but not for R 3.6. I avoid downloading r-essentials from other channels, including r as some packages have dependencies on shared library which are different between r and conda-forge channel. I prefer installing R packages using install.packages , devtools::install_github() or BiocManager command in R. 1 2 ## This did not work for R 3.6.1 # conda install -c conda-forge r-essentials Installing R and linux packages \u00b6 Here, I alternate between R and bash to install packages I use on regular basis. It is going to take a while to install these packages. You may not need to install all packages but if you are skipping ahead and get into error because of missing library, package, etc., you probably need to revisit this code block and confirm that you have all of dependencies in your environment for successful installation. 1 install.packages ( \"devtools\" ) When you start installing R packages, notice x86_64-conda_cos6-linux-gnu-cc or other compilers that R is using instead of /usr/bin/gcc or sumner-defaults. Similarly, during loading R packages which requires shared libraries, we link shared libs from conda and not from system-defaults (gcc and others). That's one of reasons I did module unload gcc before installing R packages. Eventually, we will set ~/.profile.d environment such that it will always load conda environment and ignore gcc and other devtools from system paths. Work In Progress Documentation is in alpha stage and not intended for setting up Sumner HPC environment. Backup conda env \u00b6 Base environment. 1 2 ## script is on github repo under conds/bin/ ./conda_bkup.sh","title":"Set Up Conda"},{"location":"conda/S01_conda/#first-time-login","text":"1 2 3 4 5 ssh login.sumner.jax.org ## Know OS and kernel version cat /etc/redhat-release uname -a Running CentOS Linux release 7.7.1908 (Core) Linux sumner-log2 3.10.0-1062.1.2.el7.x86_64 #1 SMP Mon Sep 30 14:19:46 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux First, login to sumner with a clean env, i.e., as it ships with default profile from HPC team, and nothing added in following files. Default bash configuration for sumner looks similar to /confs/dotfiles/hpc_default_env/ . 1 2 3 4 ~/.bashrc ~/.bash_profile ~/.bash_aliases # if it exists ~/.profile # if it exists If you had custom bash configs (linuxbrew, previous conda, etc.), comment those out from above files. If you'd linuxbrew installed, make sure to disable it unless you are confident that conda and linuxbrew can work in harmony! Same goes for ~/.local/ directory which should not exist at the fresh startup. If it does, you may have installed some tools using python, perl, or other non-root based setup scripts. For clean setup, ~/.local directory needs to be removed from user environment, i.e., either rename it to say, ~/.local_deprecated or archive it somewhere! Make sure to logout and login to sumner again for a clean env to take an effect. Once you login, your env should look something similar to this one. Note that PATH variable will default to cent os 7 standard paths and LD_LIBRARY_PATH should preferably only contain entries related to slurm scheduler. 1 2 3 4 exit #from sumner ## login again ssh login.sumner.jax.org Check common env variables set by default (HPC team) 1 2 ## paths where all executables can be found echo $PATH 1 /cm/local/apps/gcc/8.2.0/bin:/cm/shared/apps/slurm/18.08.8/sbin:/cm/shared/apps/slurm/18.08.8/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:.:/home/yoda/.local/bin:/home/yoda/bin 1 2 ## paths where shared libraries are available to run programs echo $LD_LIBRARY_PATH 1 /cm/local/apps/gcc/8.2.0/lib:/cm/local/apps/gcc/8.2.0/lib64:/cm/shared/apps/slurm/18.08.8/lib64/slurm:/cm/shared/apps/slurm/18.08.8/lib64 1 2 3 ## Used by gcc before compiling program ## Read https://stackoverflow.com/a/4250666/1243763 echo $LIBRARY_PATH 1 /cm/shared/apps/slurm/18.08.8/lib64/slurm:/cm/shared/apps/slurm/18.08.8/lib64 1 2 3 ## default loaded modules ## Most of paths in PATH, LD_LIBRARY_PATH, and LIBRARY_PATH are configured by these loaded modules. module list Currently Loaded Modules: 1) shared 2) DefaultModules 3) dot 4) default-environment 5) slurm/18.08.8 6) gcc/8.2.0 Store default hpc configuration Useful to fall back to HPC defaults if something goes awry! 1 2 3 4 5 6 7 mkdir -p ~/bkup/confs/hpc_default_env/ cp .bashrc bkup/confs/hpc_default_env/ cp .bash_profile bkup/confs/hpc_default_env/ ## export global env env | tee -a ~/bkup/confs/hpc_default_env/default_hpc_env.txt dot module only appends . to PATH variable (see module show dot ), so that you do not need to prefix ./ to run an executable file under present working directory. Since I do not need dot module, I will override default module loading by doing module unload dot in my bash configuration (later). 1 module list For now, you may add following cmd to your ~/.bash_profile . Eventually it will go to ~/.profile.d/ setup detailed below. 1 module unload dot For now, I do not need system gcc and will rely on conda-installed gcc and other devtools x86_64-conda_cos6-linux-gnu-* . More on that later but let's unload gcc first. 1 2 module unload gcc module list 1 2 Currently Loaded Modules: 1) shared 2) DefaultModules 3) default-environment 4) slurm/18.08.8 Unloading gcc Note that while starting pseudo-terminal using screen, tmux, or slurm interactive job, you may get module loaded gcc again in PATH. If so, make sure to do module unload gcc before running setup further.","title":"First-time Login"},{"location":"conda/S01_conda/#backup-and-reset-dotfiles","text":"Move dotfiles to archived directory If you have dotfiles and/or dot directories like .Renviron, .Rprofile, .curlrc, .cache, .config, etc., that may cause issues configuring environment. Moving dotfiles Following is what I've done but may not be safe unless you know what you are doing! Moving some of dotfiles is tricky as they are required for login to sumner. If you are doing this, make sure NOT to logout of sumner and at the end of executing this code block on sumner, make sure that you can login from another terminal to sumner. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 ## WARN: Moving all files and directories starting ## with dot to archived dir. mkdir -p \" ${ HOME } \" /legacy_env && \\ mv \" ${ HOME } \" /. [ ^. ] * legacy_env/ ## DO NOT FORGET TO COPY BACK following files to ## \"${HOME}\"/ else you may get locked out of sumner. cd \" ${ HOME } \" && \\ echo \"You are in home directory at $( pwd ) \" ## sumner ssh dir rsync -avhP legacy_env/.ssh ./ ## sumner login tokens, if any cp legacy_env/.vas_* ./ cp legacy_env/.bash* ./ cp legacy_env/.ksh* ./ cp legacy_env/.k5login ./ rsync -avhP legacy_env/.pki ./ rsync -avhP legacy_env/.parallel ./ ## optional files, if any ## singularity may take a larger space rsync -avhP legacy_env/.singularity ./ rsync -avhP legacy_env/.subversion ./ cp legacy_env/.emacs ./ cp legacy_env/.viminfo ./ ## make empty dirs ## note that user .local and .config, if any are now backed up and ## we are creating a empty ~/.local directory mkdir -p \" ${ HOME } \" /.cache mkdir -p \" ${ HOME } \" /.config mkdir -p \" ${ HOME } \" /.local ## CONFIRM FROM A SEPARATE TERMINAL that you can login to sumner ssh yoda@sumner env If above command succeeds and env looks similar (PATH in particular) to PATH and LD_LIBRARY_PATH shown above, you're good! You can exit old sumner session and install anaconda3 in new terminal session. Start Interactive Job prior to installation Prefer running setup on a dedicated interactive node instead of login node. Some of conda install/update steps may get killed on login node. 1 srun -p compute -q batch -N 1 -n 3 --mem 10G -t 08 :00:00 --pty bash","title":"Backup and Reset Dotfiles"},{"location":"conda/S01_conda/#install-anaconda3","text":"Python3 over Python2 Prefer using Anaconda3 (Python3) over Python2 as the latter has reached End of Life . For anaconda3: Using v2019.03-Linux-x86_64 with permalink and MD5 : b77a71c3712b45c8f33c7b2ecade366c. 1 2 3 4 5 cd \" $HOME \" && \\ mkdir -p Downloads/conda && \\ cd Downloads/conda && \\ wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ md5sum Anaconda3-2019.10-Linux-x86_64.sh Setup anaconda3 environment with default options, i.e., install at ~/anaconda3 . 1 2 cd \" $HOME \" && \\ bash ~/Downloads/conda/Anaconda3-2019.10-Linux-x86_64.sh Once conda installation is complete at default location, logout and login to sumner. Default conda env, base will now be in effect. Note (base) prefix to your username. Also, check output of following: 1 echo $CONDA_DEFAULT_ENV base 1 echo $CONDA_PREFIX /home/yoda/anaconda3","title":"Install anaconda3"},{"location":"conda/S01_conda/#configuring-conda","text":"Following are additional configuration within conda environment to enable installation of R 3.6.1+ and Jupyter.","title":"Configuring Conda"},{"location":"conda/S01_conda/#set-channel-priority","text":"Important Prefer installing compilers only from a single channel and avoid mix-and-match install. Read more at conda-forge page on channel_priority: strict which is enabled at default for conda v4.6 or higher. Add Bioconda and conda-forge channels to get updated and compbio related packages. Avoid changing order of following commands unless you prefer to keep a different priority for these channels. 1 2 3 conda config --add channels defaults conda config --add channels bioconda conda config --add channels conda-forge Above command will generate ~/.condarc file and set priority for channels, i.e., when same package is available from more than one channels, we prioritize installation per ordered channel list in ~/.condarc file as shown below. This file should be present after above commands and no need to edit unless changing priority of channels. This is in yaml format file. Please take care of preceding spaces (and not tabs) before and after - while editing this file. 1 2 3 4 channels: - conda-forge - bioconda - defaults","title":"Set channel priority"},{"location":"conda/S01_conda/#install-r-361","text":"For compatibility with conda env, prefer installing R 3.6 via conda. Prefer installing R env from conda-forge channel which is already a priority channel in our ~/.condarc . We also specify R version, just to make sure that we install R v3.6.1. Beware of non-standard conda packages Note that most up-to-date R version may be available in the same or other conda channels, like r or bioconda but it is preferable to install R from the first priority channel, i.e., conda-forge in our case, and where package does not show non-standard labels at anaconda website, e.g., As of writing this section, R 3.6.2 on anaconda website shows use of non-standard labels, most likely because it was updated a few days before and so, may not comply with all of conda dependency. 1 2 3 4 ## look for a line r-base and check source channel. ## If it is other than conda-forge, try to downgrade R package where ## r-base is available under conda-forge channel. conda install -c conda-forge r-base = 3 .6.1 Above command will take 15-30 min to resolve dependencies. It will do major overhaul of default conda environment by... upgrading conda to latest version, 4.8.2 or higher. installing conda and r-base from conda-forge source. and much more...","title":"Install R 3.6.1"},{"location":"conda/S01_conda/#pin-r-and-conda-auto-updates","text":"Before moving further, let's pin R version to 3.6.1 and also disallow conda auto-updates. That way, we have lesser chances of breaking conda env when we do conda install <pkg> in future, and carefully install/update packages without breaking existing setup. Compile over conda install Rpkg Typically, I avoid installing or updating package if conda install throws a message or warning about removing or downgrading existing packages. In such cases, I fall back to compiling package using available devtools in conda and sumner. Also, I load compiled package using Modulefile when needed, and not integrate it in my default bash environment as this may give errors while running some random program due to conflicts in shared library versions. 1 2 3 4 conda config --set auto_update_conda False ## add following to pinned file nano ~/anaconda3/conda-meta/pinned r-base ==3.6.1","title":"Pin R and conda auto-updates"},{"location":"conda/S01_conda/#setup-rprofile-and-renviron","text":"Setup R package directory path for R 3.6 1 mkdir -p ~/R/pkgs/v3.6 Create these two files to setup startup env for R Renviron 1 nano ~/.Renviron Where should R save new packages? Over time, this directory may grow in size, so better to keep under tier1 storage. 1 R_LIBS = \"/projects/verhaak-lab/yoda/sumnerenv_os7/R/pkgs/v3.6:/home/yoda/R/pkgs/v3.6:/home/yoda/anaconda3/lib/R/library\" You can confirm precedence of R library paths in R using .libPaths() command. Note that /home/yoda/anaconda3/lib/R/library is a required path set while installing R using conda. R profile 1 nano ~/.Rprofile 1 2 3 4 5 6 7 8 9 10 ## set user specific env variables, if any here ## e.g., GITHUB_PAT if here Sys.setenv(\"GITHUB_PAT\"=\"xyzabc1234\") ## Default source to download packages local({ r <- getOption(\"repos\") r[\"CRAN\"] <- \"https://cran.rstudio.com\" options(repos = r) }) Before further configuring sumner env, let's logout and login first from interactive job and exit sumner. Then, login back to sumner and start interactive queue again. 1 2 3 4 5 6 7 exit # from interactive session exit # from sumner ssh sumner ## start interactive session srun -p compute -q batch -N 1 -n 3 --mem 10G -t 08 :00:00 --pty bash Confirm that login env is similar to earlier env (just after anaconda3 setup) by running env command. PATH should now have paths related to conda env prefixed but nothing else related to modules, LD_LIBRARY_PATH, etc. Also, make sure that module: gcc is unloaded. We do not want system gcc (or any other devtools), and instead rely on conda-installed devtools. 1 2 3 4 5 6 ## unload gcc if loaded module unload gcc ## example PATH variable /home/yoda/anaconda3/bin:/home/yoda/anaconda3/condabin:/cm/shared/apps/slurm/18.08.8/sbin:/cm/shared/apps/slurm/18.08.8/bin :/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/yoda/.local/bin:/home/yoda/bin Avoid Rpkgs using conda install Install essential R packages and jupyter kernel for R only if they are available for R 3.6.x (preferably v3.6.1) from conda-forge channel. This may not be a case for most times, e.g., for R v3.5.1, I can find compatible packages but not for R 3.6. I avoid downloading r-essentials from other channels, including r as some packages have dependencies on shared library which are different between r and conda-forge channel. I prefer installing R packages using install.packages , devtools::install_github() or BiocManager command in R. 1 2 ## This did not work for R 3.6.1 # conda install -c conda-forge r-essentials","title":"Setup Rprofile and Renviron"},{"location":"conda/S01_conda/#installing-r-and-linux-packages","text":"Here, I alternate between R and bash to install packages I use on regular basis. It is going to take a while to install these packages. You may not need to install all packages but if you are skipping ahead and get into error because of missing library, package, etc., you probably need to revisit this code block and confirm that you have all of dependencies in your environment for successful installation. 1 install.packages ( \"devtools\" ) When you start installing R packages, notice x86_64-conda_cos6-linux-gnu-cc or other compilers that R is using instead of /usr/bin/gcc or sumner-defaults. Similarly, during loading R packages which requires shared libraries, we link shared libs from conda and not from system-defaults (gcc and others). That's one of reasons I did module unload gcc before installing R packages. Eventually, we will set ~/.profile.d environment such that it will always load conda environment and ignore gcc and other devtools from system paths. Work In Progress Documentation is in alpha stage and not intended for setting up Sumner HPC environment.","title":"Installing R and linux packages"},{"location":"conda/S01_conda/#backup-conda-env","text":"Base environment. 1 2 ## script is on github repo under conds/bin/ ./conda_bkup.sh","title":"Backup conda env"},{"location":"confs/","text":"Configuration files \u00b6 Configuration files used during setup. Please do not copy and paste without reading documentation else this may break your login environment.","title":"Home"},{"location":"confs/#configuration-files","text":"Configuration files used during setup. Please do not copy and paste without reading documentation else this may break your login environment.","title":"Configuration files"},{"location":"confs/dotfiles/","text":"dotfiles \u00b6 Configuration files used during setup. Please do not copy and paste without reading documentation else this may break your login environment.","title":"Home"},{"location":"confs/dotfiles/#dotfiles","text":"Configuration files used during setup. Please do not copy and paste without reading documentation else this may break your login environment.","title":"dotfiles"},{"location":"confs/dotfiles/hpc_default_env/","text":"Example default dotfiles under user's home directory. File contents may differ.","title":"Default dotfiles"},{"location":"containers/S01_containers/","text":"Singularity","title":"Getting Started"},{"location":"containers/ensembl-vep/","text":"For HPC Sumner at JAX @sbamin Install VEP via docker \u00b6 Download docker image for vep and convert to singularity .sif format 1 2 ## v99.2 but may vary for future dates singularity run ensembl-vep_latest Converted image should be under followig path. 1 find \" $SINGULARITY_CACHEDIR \" -type f -name \"ensembl-vep_latest.sif\" I've copied converted sif images to a separate directory and exported directory path as SINGULARITY_SIF env variable. I've renamed ensembl-vep_latest.sif to ensembl-vep_v99.2.sif . Download offline VEP cache \u00b6 To speed up annotations, download vep cache matching vep version downloaded earlier, i.e., v99. See details for downloading cache. cache size can go in several GBs, so save under tier1. 1 2 3 4 5 6 7 8 cd \" $RVANNOT \" /vep_core/v99 curl -O ftp://ftp.ensembl.org/pub/release-99/variation/indexed_vep_cache/homo_sapiens_vep_99_GRCh38.tar.gz ## approx. 14GB ## MD5: a2a8edfe72ffa659242e66d414027701 homo_sapiens_vep_99_GRCh38.tar.gz ## extract cache tar xzf homo_sapiens_vep_99_GRCh38.tar.gz IMPORTANT: Using hg19/GRCh37 \u00b6 If VCFs for annotations require hg19/GRCh37 assembly, you need to install valid cache for Grch37 assembly. Read discussion here . 1 2 3 4 5 6 7 8 cd \" $RVANNOT \" /vep_core/v99 curl -O ftp://ftp.ensembl.org/pub/release-99/variation/indexed_vep_cache/homo_sapiens_vep_99_GRCh37.tar.gz ## approx. 13GB ## MD5: 72928de96075666a4477cbd4430084c9 homo_sapiens_vep_99_GRCh37.tar.gz ## extract cache tar xzf homo_sapiens_vep_99_GRCh37.tar.gz Run VEP in offline mode \u00b6 Use downloaded cache instead of running in --database mode. The latter will fetch data from online Ensemble database and can be very slow. For detailed arguments, read VEP manpage NOTE: Using --assembly GRCh37 here for hg19 coordinates. Omitting it will default to the most current assembly, GRCh38. 1 2 3 singularity run \" ${ SINGULARITY_SIF } \" /ensembl-vep_v99.2.sif vep --offline --dir_cache \" ${ RVANNOT } /vep_core/v99\" --species homo_sapiens --assembly GRCh37 --compress_output gzip -o ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20160830.somatic.snv_mnv.vep.vcf.gz -i /projects/verhaak-lab/ecdna/datasets/pcawg/dump/final_consensus_12oct/icgc/snv_mnv/ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20160830.somatic.snv_mnv.vcf.gz singularity run \" ${ SINGULARITY_SIF } \" /ensembl-vep_v99.2.sif vep --offline --dir_cache \" ${ RVANNOT } /vep_core/v99\" --species homo_sapiens --assembly GRCh37 --compress_output gzip -o ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20161006.somatic.indel.vep.vcf.gz -offline -i /projects/verhaak-lab/ecdna/datasets/pcawg/dump/final_consensus_12oct/icgc/indel/ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20161006.somatic.indel.vcf.gz END","title":"How to run VEP using singularity"},{"location":"containers/ensembl-vep/#install-vep-via-docker","text":"Download docker image for vep and convert to singularity .sif format 1 2 ## v99.2 but may vary for future dates singularity run ensembl-vep_latest Converted image should be under followig path. 1 find \" $SINGULARITY_CACHEDIR \" -type f -name \"ensembl-vep_latest.sif\" I've copied converted sif images to a separate directory and exported directory path as SINGULARITY_SIF env variable. I've renamed ensembl-vep_latest.sif to ensembl-vep_v99.2.sif .","title":"Install VEP via docker"},{"location":"containers/ensembl-vep/#download-offline-vep-cache","text":"To speed up annotations, download vep cache matching vep version downloaded earlier, i.e., v99. See details for downloading cache. cache size can go in several GBs, so save under tier1. 1 2 3 4 5 6 7 8 cd \" $RVANNOT \" /vep_core/v99 curl -O ftp://ftp.ensembl.org/pub/release-99/variation/indexed_vep_cache/homo_sapiens_vep_99_GRCh38.tar.gz ## approx. 14GB ## MD5: a2a8edfe72ffa659242e66d414027701 homo_sapiens_vep_99_GRCh38.tar.gz ## extract cache tar xzf homo_sapiens_vep_99_GRCh38.tar.gz","title":"Download offline VEP cache"},{"location":"containers/ensembl-vep/#important-using-hg19grch37","text":"If VCFs for annotations require hg19/GRCh37 assembly, you need to install valid cache for Grch37 assembly. Read discussion here . 1 2 3 4 5 6 7 8 cd \" $RVANNOT \" /vep_core/v99 curl -O ftp://ftp.ensembl.org/pub/release-99/variation/indexed_vep_cache/homo_sapiens_vep_99_GRCh37.tar.gz ## approx. 13GB ## MD5: 72928de96075666a4477cbd4430084c9 homo_sapiens_vep_99_GRCh37.tar.gz ## extract cache tar xzf homo_sapiens_vep_99_GRCh37.tar.gz","title":"IMPORTANT: Using hg19/GRCh37"},{"location":"containers/ensembl-vep/#run-vep-in-offline-mode","text":"Use downloaded cache instead of running in --database mode. The latter will fetch data from online Ensemble database and can be very slow. For detailed arguments, read VEP manpage NOTE: Using --assembly GRCh37 here for hg19 coordinates. Omitting it will default to the most current assembly, GRCh38. 1 2 3 singularity run \" ${ SINGULARITY_SIF } \" /ensembl-vep_v99.2.sif vep --offline --dir_cache \" ${ RVANNOT } /vep_core/v99\" --species homo_sapiens --assembly GRCh37 --compress_output gzip -o ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20160830.somatic.snv_mnv.vep.vcf.gz -i /projects/verhaak-lab/ecdna/datasets/pcawg/dump/final_consensus_12oct/icgc/snv_mnv/ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20160830.somatic.snv_mnv.vcf.gz singularity run \" ${ SINGULARITY_SIF } \" /ensembl-vep_v99.2.sif vep --offline --dir_cache \" ${ RVANNOT } /vep_core/v99\" --species homo_sapiens --assembly GRCh37 --compress_output gzip -o ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20161006.somatic.indel.vep.vcf.gz -offline -i /projects/verhaak-lab/ecdna/datasets/pcawg/dump/final_consensus_12oct/icgc/indel/ffe4bb51-e98a-41a7-a4e1-c3970386889c.consensus.20161006.somatic.indel.vcf.gz END","title":"Run VEP in offline mode"},{"location":"slurm/S01_slurm101/","text":"Slurm cheatsheet","title":"Working with Slurm"}]}